{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/absolute/path/to/gesture_recognizer.task'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogui\n",
      "  Downloading PyAutoGUI-0.9.54.tar.gz (61 kB)\n",
      "     ---------------------------------------- 61.2/61.2 kB 3.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pyscreeze>=0.1.21\n",
      "  Downloading PyScreeze-0.1.30.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pygetwindow>=0.0.5\n",
      "  Downloading PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pymsgbox\n",
      "  Downloading PyMsgBox-1.0.9.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pytweening>=1.0.4\n",
      "  Downloading pytweening-1.0.7.tar.gz (168 kB)\n",
      "     -------------------------------------- 168.2/168.2 kB 9.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mouseinfo\n",
      "  Downloading MouseInfo-0.1.3.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyrect\n",
      "  Downloading PyRect-0.2.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Pillow>=9.2.0 in c:\\users\\bluecom011\\miniconda3\\envs\\mp\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (9.4.0)\n",
      "Collecting pyperclip\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pyautogui, pygetwindow, pyscreeze, pytweening, mouseinfo, pymsgbox, pyperclip, pyrect\n",
      "  Building wheel for pyautogui (pyproject.toml): started\n",
      "  Building wheel for pyautogui (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyautogui: filename=PyAutoGUI-0.9.54-py3-none-any.whl size=37597 sha256=e27bab0bd99b25c9b1f864a508abcb7e373293c9d115b253071fe1c90e49be88\n",
      "  Stored in directory: c:\\users\\bluecom011\\appdata\\local\\pip\\cache\\wheels\\77\\b5\\ac\\1302e810eeb1ef39834fe78b5bac41c8bc2f7d57f03720ef5c\n",
      "  Building wheel for pygetwindow (setup.py): started\n",
      "  Building wheel for pygetwindow (setup.py): finished with status 'done'\n",
      "  Created wheel for pygetwindow: filename=PyGetWindow-0.0.9-py3-none-any.whl size=11079 sha256=55b88ef807d82173e9f8792e3eb48abe437c17975dbfb90f9b8607b96d19e3a2\n",
      "  Stored in directory: c:\\users\\bluecom011\\appdata\\local\\pip\\cache\\wheels\\72\\4e\\f0\\cdd2f4c5ade082fab3502584ffbf1ea95a2c904a781afb087e\n",
      "  Building wheel for pyscreeze (pyproject.toml): started\n",
      "  Building wheel for pyscreeze (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyscreeze: filename=PyScreeze-0.1.30-py3-none-any.whl size=14400 sha256=bb635ccde66324dae5f17819473c73b5f61fd7c9337b58ccda6fee3cb1e2b438\n",
      "  Stored in directory: c:\\users\\bluecom011\\appdata\\local\\pip\\cache\\wheels\\be\\5e\\30\\a507b7801ccc9f6b69c7a25136f9142eb0da37ce74f696bea7\n",
      "  Building wheel for pytweening (setup.py): started\n",
      "  Building wheel for pytweening (setup.py): finished with status 'done'\n",
      "  Created wheel for pytweening: filename=pytweening-1.0.7-py3-none-any.whl size=6214 sha256=9675dc75eae4b61cec024c97972579ff2eb0bd062186b748f90a7896eae27933\n",
      "  Stored in directory: c:\\users\\bluecom011\\appdata\\local\\pip\\cache\\wheels\\ea\\50\\90\\7695b69ae7f9e2abdf1aaccb9b111316dda56c87a9c87f32a7\n",
      "  Building wheel for mouseinfo (setup.py): started\n",
      "  Building wheel for mouseinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for mouseinfo: filename=MouseInfo-0.1.3-py3-none-any.whl size=10906 sha256=987a334e3b2b3eac8f179654a122bdeb9a4970264eae1dbdfcf1960e287293b2\n",
      "  Stored in directory: c:\\users\\bluecom011\\appdata\\local\\pip\\cache\\wheels\\cc\\b3\\70\\c17a54ab01ad15d3bf0df27ba050624e03a2f7a00a9f18d6a0\n",
      "  Building wheel for pymsgbox (pyproject.toml): started\n",
      "  Building wheel for pymsgbox (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pymsgbox: filename=PyMsgBox-1.0.9-py3-none-any.whl size=7416 sha256=006cdf865f662336205f5daa645f9b604279a5d5a5cd74832429968f833b946b\n",
      "  Stored in directory: c:\\users\\bluecom011\\appdata\\local\\pip\\cache\\wheels\\c3\\e8\\92\\1856c0c3eb1f38bfa3c422f859271cc7f50c59c5a77356e86e\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=edca56291b2304f0bdf936119de22fa0ec56ea7b4760939a8f181382c3c2b068\n",
      "  Stored in directory: c:\\users\\bluecom011\\appdata\\local\\pip\\cache\\wheels\\36\\86\\43\\c32981b55b0d0a78b9762fd4fa7d6de0da0a46fd035cedfccb\n",
      "  Building wheel for pyrect (setup.py): started\n",
      "  Building wheel for pyrect (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrect: filename=PyRect-0.2.0-py2.py3-none-any.whl size=11205 sha256=38465e3748ed93353e8dd7ec678b2d296bc10cebabf7651cdd11d964b4146ee1\n",
      "  Stored in directory: c:\\users\\bluecom011\\appdata\\local\\pip\\cache\\wheels\\a1\\a4\\9e\\93e92e16db716e372b2154a7e95eec5312234dd7ade9a47c7c\n",
      "Successfully built pyautogui pygetwindow pyscreeze pytweening mouseinfo pymsgbox pyperclip pyrect\n",
      "Installing collected packages: pytweening, pyrect, pyperclip, pymsgbox, pyscreeze, pygetwindow, mouseinfo, pyautogui\n",
      "Successfully installed mouseinfo-0.1.3 pyautogui-0.9.54 pygetwindow-0.0.9 pymsgbox-1.0.9 pyperclip-1.8.2 pyrect-0.2.0 pyscreeze-0.1.30 pytweening-1.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyautogui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "# 한글 출력을 위한 함수\n",
    "def draw_korean_text(image, text, position, font_path, font_size, color):\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "    return cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# mediapipe 초기 설정\n",
    "mp_face = mp.solutions.face_mesh\n",
    "face_mesh = mp_face.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "prev_x, prev_y = 0, 0\n",
    "\n",
    "# 눈 감지 관련 변수\n",
    "eyes_closed = False\n",
    "time_eyes_closed = 0\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"  # 여기에 사용할 한글 폰트의 경로를 지정하세요.\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image_rgb)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for landmarks in results.multi_face_landmarks:\n",
    "                left_eye_top = (landmarks.landmark[159].x, landmarks.landmark[159].y)\n",
    "                left_eye_bottom = (landmarks.landmark[145].x, landmarks.landmark[145].y)\n",
    "                right_eye_top = (landmarks.landmark[386].x, landmarks.landmark[386].y)\n",
    "                right_eye_bottom = (landmarks.landmark[374].x, landmarks.landmark[374].y)\n",
    "                left_eye_distance = abs(left_eye_top[1] - left_eye_bottom[1])\n",
    "                right_eye_distance = abs(right_eye_top[1] - right_eye_bottom[1])\n",
    "                \n",
    "                if left_eye_distance < 0.02 and right_eye_distance < 0.02:\n",
    "                    if not eyes_closed:\n",
    "                        eyes_closed = True\n",
    "                        time_eyes_closed = time.time()\n",
    "                else:\n",
    "                    if eyes_closed and time.time() - time_eyes_closed > 0.3:\n",
    "                        pyautogui.doubleClick()\n",
    "                        image = draw_korean_text(image, \"눈 깜빡임 마우스 클릭\", (50, 50), font_path, 30, (0, 255, 0))\n",
    "                        eyes_closed = False\n",
    "                        \n",
    "                x = int(landmarks.landmark[4].x * image.shape[1])\n",
    "                y = int(landmarks.landmark[4].y * image.shape[0])\n",
    "                \n",
    "                if prev_x and prev_y:\n",
    "                    diff_x = -prev_x\n",
    "                    diff_y = -prev_y\n",
    "                    pyautogui.move(diff_x * 3, diff_y * 3)\n",
    "                    image = draw_korean_text(image, \"AI 얼굴 방향 마우스 인식중..\", (50, 100), font_path, 30, (0, 0, 255))\n",
    "                    \n",
    "                prev_x, prev_y = x, y\n",
    "                mp_drawing.draw_landmarks(image, landmarks, mp_face.FACEMESH_TESSELATION, landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255)))\n",
    "        \n",
    "        cv2.imshow('MediaPipe FaceMesh', image)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얼굴 방향으로 마우스 커서 움직이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "# 한글 출력을 위한 함수\n",
    "def draw_korean_text(image, text, position, font_path, font_size, color):\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "    return cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# mediapipe 초기 설정\n",
    "mp_face = mp.solutions.face_mesh\n",
    "face_mesh = mp_face.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "prev_x, prev_y = 0, 0\n",
    "\n",
    "# 눈 감지 관련 변수\n",
    "눈을_감은_상태 = False\n",
    "눈을_감은_시간 = 0\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"  # 여기에 사용할 한글 폰트의 경로를 지정하세요.\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        성공, 이미지 = cap.read()\n",
    "        if not 성공:\n",
    "            print(\"카메라 프레임이 비어있습니다.\")\n",
    "            continue\n",
    "        이미지_rgb = cv2.cvtColor(이미지, cv2.COLOR_BGR2RGB)\n",
    "        결과 = face_mesh.process(이미지_rgb)\n",
    "        \n",
    "        if 결과.multi_face_landmarks:\n",
    "            for 랜드마크 in 결과.multi_face_landmarks:\n",
    "                왼쪽_눈_위 = (랜드마크.landmark[159].x * 이미지.shape[1], 랜드마크.landmark[159].y * 이미지.shape[0])\n",
    "                왼쪽_눈_아래 = (랜드마크.landmark[145].x * 이미지.shape[1], 랜드마크.landmark[145].y * 이미지.shape[0])\n",
    "                오른쪽_눈_위 = (랜드마크.landmark[386].x * 이미지.shape[1], 랜드마크.landmark[386].y * 이미지.shape[0])\n",
    "                오른쪽_눈_아래 = (랜드마크.landmark[374].x * 이미지.shape[1], 랜드마크.landmark[374].y * 이미지.shape[0])\n",
    "                왼쪽_눈_거리 = abs(왼쪽_눈_위[1] - 왼쪽_눈_아래[1])\n",
    "                오른쪽_눈_거리 = abs(오른쪽_눈_위[1] - 오른쪽_눈_아래[1])\n",
    "                \n",
    "                if 왼쪽_눈_거리 < 0.02 and 오른쪽_눈_거리 < 0.02:\n",
    "                    if not 눈을_감은_상태:\n",
    "                        눈을_감은_상태 = True\n",
    "                        눈을_감은_시간 = time.time()\n",
    "                else:\n",
    "                    if 눈을_감은_상태 and time.time() - 눈을_감은_시간 > 0.3:\n",
    "                        pyautogui.click()  # Use click() instead of doubleClick()\n",
    "                        이미지 = draw_korean_text(이미지, \"눈 깜빡임 마우스 클릭\", (50, 50), font_path, 30, (0, 255, 0))\n",
    "                        눈을_감은_상태 = False\n",
    "                        \n",
    "                마우스_x = int((왼쪽_눈_위[0] + 오른쪽_눈_위[0]) / 2)\n",
    "                마우스_y = int((왼쪽_눈_위[1] + 오른쪽_눈_위[1]) / 2)\n",
    "                \n",
    "                if prev_x and prev_y:\n",
    "                    diff_x = 마우스_x - prev_x\n",
    "                    diff_y = 마우스_y - prev_y\n",
    "                    pyautogui.move(diff_x * 3, diff_y * 3)\n",
    "                    이미지 = draw_korean_text(이미지, \"AI 얼굴 방향 마우스 인식중..\", (50, 100), font_path, 30, (0, 0, 255))\n",
    "                    \n",
    "                prev_x, prev_y = 마우스_x, 마우스_y\n",
    "                mp_drawing.draw_landmarks(이미지, 랜드마크, mp_face.FACEMESH_TESSELATION, landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255)))\n",
    "        \n",
    "        cv2.imshow('MediaPipe FaceMesh', 이미지)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "# 한글 출력을 위한 함수\n",
    "def draw_korean_text(image, text, position, font_path, font_size, color):\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "    return cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Mediapipe 초기화 - Hands 모델 사용\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "prev_x, prev_y = 0, 0\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"  # 사용할 한글 폰트의 경로를 지정하세요.\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"카메라 프레임이 비어있습니다.\")\n",
    "            continue\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # 손목의 중간 지점을 마우스 좌표로 사용\n",
    "                wrist = (int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * image.shape[1]),\n",
    "                         int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * image.shape[0]))\n",
    "\n",
    "                # 마우스 이동\n",
    "                if prev_x and prev_y:\n",
    "                    diff_x = wrist[0] - prev_x\n",
    "                    diff_y = wrist[1] - prev_y\n",
    "                    pyautogui.move(diff_x * 3, diff_y * 3)\n",
    "                    image = draw_korean_text(image, \"손으로 마우스 이동 중..\", (50, 100), font_path, 30, (0, 0, 255))\n",
    "\n",
    "                prev_x, prev_y = wrist\n",
    "\n",
    "                # 손 인식 결과 그리기\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                          landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255)))\n",
    "        \n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 한글 출력을 위한 함수\n",
    "def draw_korean_text(image, text, position, font_path, font_size, color):\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "    return cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# 손 인식 모델 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "prev_x, prev_y = 0, 0\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"  # 사용할 한글 폰트의 경로를 지정하세요.\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"카메라 프레임이 비어있습니다.\")\n",
    "            continue\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # 손목의 중간 지점을 마우스 좌표로 사용\n",
    "                wrist = (int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * image.shape[1]),\n",
    "                         int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * image.shape[0]))\n",
    "\n",
    "                # 마우스 이동\n",
    "                if prev_x and prev_y:\n",
    "                    diff_x = wrist[0] - prev_x\n",
    "                    diff_y = wrist[1] - prev_y\n",
    "                    pyautogui.move(diff_x * 3, diff_y * 3)\n",
    "                    image = draw_korean_text(image, \"손으로 마우스 이동 중..\", (50, 100), font_path, 30, (0, 0, 255))\n",
    "\n",
    "                # 손을 움켜쥔 상태 확인\n",
    "                thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "                ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "                pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "                # 각 손가락 끝 지점의 좌표를 numpy array로 변환\n",
    "                thumb_tip_np = np.array([thumb_tip.x, thumb_tip.y])\n",
    "                index_tip_np = np.array([index_tip.x, index_tip.y])\n",
    "                middle_tip_np = np.array([middle_tip.x, middle_tip.y])\n",
    "                ring_tip_np = np.array([ring_tip.x, ring_tip.y])\n",
    "                pinky_tip_np = np.array([pinky_tip.x, pinky_tip.y])\n",
    "\n",
    "                # 손가락 사이의 각도 계산\n",
    "                angle_index_thumb = math.degrees(math.atan2(index_tip_np[1] - thumb_tip_np[1], index_tip_np[0] - thumb_tip_np[0]))\n",
    "                angle_middle_index = math.degrees(math.atan2(middle_tip_np[1] - index_tip_np[1], middle_tip_np[0] - index_tip_np[0]))\n",
    "                angle_ring_middle = math.degrees(math.atan2(ring_tip_np[1] - middle_tip_np[1], ring_tip_np[0] - middle_tip_np[0]))\n",
    "                angle_pinky_ring = math.degrees(math.atan2(pinky_tip_np[1] - ring_tip_np[1], pinky_tip_np[0] - ring_tip_np[0]))\n",
    "\n",
    "                # 각 손가락 간의 평균 각도 계산\n",
    "                avg_angle = (angle_index_thumb + angle_middle_index + angle_ring_middle + angle_pinky_ring) / 4\n",
    "\n",
    "                # 특정 각도 이하로 움켜쥔 경우에 마우스 클릭\n",
    "                if avg_angle < 20:\n",
    "                    pyautogui.click()\n",
    "                    image = draw_korean_text(image, \"손을 움켜쥼으로 클릭\", (50, 150), font_path, 30, (255, 0, 0))\n",
    "\n",
    "                prev_x, prev_y = wrist\n",
    "\n",
    "                # 손 인식 결과 그리기\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                          landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255)))\n",
    "        \n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 한글 출력을 위한 함수\n",
    "def draw_korean_text(image, text, position, font_path, font_size, color):\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "    return cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# 손 인식 모델 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "prev_x, prev_y = 0, 0\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"  # 사용할 한글 폰트의 경로를 지정하세요.\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"카메라 프레임이 비어있습니다.\")\n",
    "            continue\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "        \n",
    "        if results.multi_hand_landmarks and len(results.multi_hand_landmarks) == 2:\n",
    "            hand_landmarks_1 = results.multi_hand_landmarks[0]\n",
    "            hand_landmarks_2 = results.multi_hand_landmarks[1]\n",
    "\n",
    "            # 검지 손가락 끝 부분 좌표\n",
    "            index_finger_tip_1 = hand_landmarks_1.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            index_finger_tip_2 = hand_landmarks_2.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            \n",
    "            index_finger_tip_1_np = np.array([index_finger_tip_1.x * image.shape[1], index_finger_tip_1.y * image.shape[0]])\n",
    "            index_finger_tip_2_np = np.array([index_finger_tip_2.x * image.shape[1], index_finger_tip_2.y * image.shape[0]])\n",
    "\n",
    "            # 두 손가락 간의 거리 계산\n",
    "            fingers_distance = np.linalg.norm(index_finger_tip_1_np - index_finger_tip_2_np)\n",
    "\n",
    "            # 마우스 이동\n",
    "            if prev_x and prev_y:\n",
    "                diff_x = (index_finger_tip_1_np[0] + index_finger_tip_2_np[0]) / 2 - prev_x\n",
    "                diff_y = (index_finger_tip_1_np[1] + index_finger_tip_2_np[1]) / 2 - prev_y\n",
    "                pyautogui.move(diff_x * 3, diff_y * 3)\n",
    "                image = draw_korean_text(image, \"손가락으로 마우스 이동 중..\", (50, 100), font_path, 30, (0, 0, 255))\n",
    "\n",
    "            # 손가락을 활짝 펴면 클릭\n",
    "            if fingers_distance > 150:\n",
    "                pyautogui.click()\n",
    "                image = draw_korean_text(image, \"손을 펴고 클릭\", (50, 150), font_path, 30, (255, 0, 0))\n",
    "\n",
    "            prev_x, prev_y = (index_finger_tip_1_np[0] + index_finger_tip_2_np[0]) / 2, (index_finger_tip_1_np[1] + index_finger_tip_2_np[1]) / 2\n",
    "\n",
    "            # 손 인식 결과 그리기\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks_1, mp_hands.HAND_CONNECTIONS,\n",
    "                                      landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255)))\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks_2, mp_hands.HAND_CONNECTIONS,\n",
    "                                      landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255)))\n",
    "        \n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
