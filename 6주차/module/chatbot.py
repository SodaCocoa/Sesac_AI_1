# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from keras.models import load_model  # TensorFlow ë°±ì—”ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” Keras ëª¨ë¸ì„ ë¡œë“œí•˜ê¸° ìœ„í•´ í•„ìš”
from PIL import Image, ImageOps  # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬, PIL ëŒ€ì‹  pillowë¥¼ ì‚¬ìš©
import numpy as np  # ìˆ˜ì¹˜ ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st  # ì›¹ ì•±ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from dotenv import load_dotenv  # í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os  # ìš´ì˜ ì²´ì œì™€ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬, í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© ì‹œ í•„ìš”
import openai  # OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from openai import OpenAI  # OpenAI í´ë˜ìŠ¤ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„í¬íŠ¸

# API í‚¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ë³´ì•ˆìƒì˜ ì´ìœ ë¡œ ì‹¤ì œ í‚¤ ê°’ì„ ì½”ë“œì— ì§ì ‘ ë„£ì§€ ì•ŠìŠµë‹ˆë‹¤.
key = '  '

# Streamlit ì•±ì˜ ë©”ì¸ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def app():

    st.title("ğŸŒ±ğŸ’¬  SESAC BOT")  # ì•± íƒ€ì´í‹€ ì„¤ì •

    # OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    client = OpenAI(api_key=key)

    # Streamlit ì„¸ì…˜ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡ì˜ ë©”ì‹œì§€ ê¸°ë¡ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
    # 'messages'ê°€ ì„¸ì…˜ ìƒíƒœì— ì—†ê±°ë‚˜ ë¹„ì–´ìˆë‹¤ë©´, ê¸°ë³¸ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    if "messages" not in st.session_state or not st.session_state.messages:
        # ì´ˆê¸° ë©”ì‹œì§€ë¡œ 'ë¶ˆë²• ì£¼ì°¨ì…ë‹ˆë‹¤.'ë¼ëŠ” ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        st.session_state.messages = [
            {"role": "assistant", "content": "ë¶ˆë²• ì£¼ì°¨ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê³¼íƒœë£Œê°€ 10ë§Œì›ì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¦‰ì‹œ ì°¨ëŸ‰ì„ ë¹¼ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."}
            ]
        
        
        # ì´ˆê¸° ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
        #with st.chat_message("assistant"):
            #st.markdown("ë¶ˆë²• ì£¼ì°¨ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ")

    # ì €ì¥ëœ ì±— ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
    for message in st.session_state.messages:
        if message["role"] == "system":
            continue  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ë¬´ì‹œí•©ë‹ˆë‹¤.
        with st.chat_message(message["role"]):  # ì‚¬ìš©ì ë˜ëŠ” ì±—ë´‡ì˜ ì—­í• ì— ë”°ë¼ ë©”ì‹œì§€ë¥¼ êµ¬ë¶„í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.
    if prompt := st.chat_input("í•˜ê³  ì‹¶ì€ ë§ ì…ë ¥"):
        # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•©ë‹ˆë‹¤.
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):  # ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ ì…ë ¥ì„ í‘œì‹œí•©ë‹ˆë‹¤.
            st.markdown(prompt)
        with st.chat_message("assistant"):  # ì±—ë´‡ì˜ ì‘ë‹µì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
            message_placeholder = st.empty()  # ì‘ë‹µì„ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•œ ì„ì‹œ í”Œë ˆì´ìŠ¤í™€ë”
            full_response = ""  # ì‘ë‹µ ë‚´ìš©ì„ ì €ì¥í•  ë³€ìˆ˜

            # ì‚¬ìš©ì ì…ë ¥ì— "ë¶ˆë²•"ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë¨¼ì € ì±—ë´‡ì´ "ëª°ë£¨"ë¼ê³  ì‘ë‹µí•©ë‹ˆë‹¤.
            if "ë²Œê¸ˆ" in prompt:
                full_response += "ë¶ˆë²• ì£¼ì°¨ì— ëŒ€í•œ ë²Œê¸ˆ ë¶€ê³¼ì™€ ê´€ë ¨í•˜ì—¬ ì´ì˜ê°€ ìˆìœ¼ì‹œë‹¤ë©´, í•´ë‹¹ ê¸°ê´€ì— ë¬¸ì˜í•˜ì—¬ ìƒí™©ì„ ì„¤ëª…í•˜ê³  í•„ìš”í•œ ì ˆì°¨ë¥¼ ì§„í–‰í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
                message_placeholder.markdown(full_response)
            elif "ë²Œê¸ˆ" in prompt:
                full_response += "ë¶ˆë²• ì£¼ì°¨ì— ëŒ€í•œ ë²Œê¸ˆ ë¶€ê³¼ì™€ ê´€ë ¨í•˜ì—¬ ì´ì˜ê°€ ìˆìœ¼ì‹œë‹¤ë©´, í•´ë‹¹ ê¸°ê´€ì— ë¬¸ì˜í•˜ì—¬ ìƒí™©ì„ ì„¤ëª…í•˜ê³  í•„ìš”í•œ ì ˆì°¨ë¥¼ ì§„í–‰í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
                message_placeholder.markdown(full_response)
            else:
                # OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡ì˜ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
                response = client.chat.completions.create(
                    model="gpt-4-turbo-preview",  # ì‚¬ìš©í•  ëª¨ë¸
                    messages=[
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.messages
                    ],
                    stream=True,  # ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¼(ì‹¤ì‹œê°„ìœ¼ë¡œ) ë°›ìŠµë‹ˆë‹¤.
                )

                # OpenAI APIë¡œë¶€í„° ë°›ì€ ì‘ë‹µì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
                for delta in response:
                    # ì‘ë‹µ ë‚´ìš©ì„ ì¡°í•©í•˜ì—¬ full_responseë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                    full_response += delta.choices[0].delta.content if delta.choices[0].delta.content else ""
                    message_placeholder.markdown(full_response + "â–Œ")  # ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œí•˜ê³ , ì…ë ¥ ì¤‘ì„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

            message_placeholder.markdown(full_response)  # ìµœì¢… ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.

        # ì±—ë´‡ì˜ ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•©ë‹ˆë‹¤.
        st.session_state.messages.append({"role": "assistant", "content": full_response})

