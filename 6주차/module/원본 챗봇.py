# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from keras.models import load_model  # TensorFlow ë°±ì—”ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” Keras ëª¨ë¸ì„ ë¡œë“œí•˜ê¸° ìœ„í•´ í•„ìš”
from PIL import Image, ImageOps  # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬, PIL ëŒ€ì‹  pillowë¥¼ ì‚¬ìš©
import numpy as np  # ìˆ˜ì¹˜ ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st  # ì›¹ ì•±ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from dotenv import load_dotenv  # í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os  # ìš´ì˜ ì²´ì œì™€ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬, í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© ì‹œ í•„ìš”
import openai  # OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from openai import OpenAI  # OpenAI í´ë˜ìŠ¤ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„í¬íŠ¸

# API í‚¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ë³´ì•ˆìƒì˜ ì´ìœ ë¡œ ì‹¤ì œ í‚¤ ê°’ì„ ì½”ë“œì— ì§ì ‘ ë„£ì§€ ì•ŠìŠµë‹ˆë‹¤.
key = ' '

# Streamlit ì•±ì˜ ë©”ì¸ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def app():

    st.title("ğŸŒ±ğŸ’¬  SESAC BOT")  # ì•± íƒ€ì´í‹€ ì„¤ì •

    # OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ OpenAI APIì™€ ìƒí˜¸ì‘ìš©í•©ë‹ˆë‹¤.
    client = OpenAI(api_key=key)

    # Streamlit ì„¸ì…˜ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡ì˜ ë©”ì‹œì§€ ê¸°ë¡ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
    # 'messages'ê°€ ì„¸ì…˜ ìƒíƒœì— ì—†ë‹¤ë©´ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ì €ì¥ëœ ì±— ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
    for message in st.session_state.messages:
        if message["role"] == "system":
            continue  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ë¬´ì‹œí•©ë‹ˆë‹¤.
        with st.chat_message(message["role"]):  # ì‚¬ìš©ì ë˜ëŠ” ì±—ë´‡ì˜ ì—­í• ì— ë”°ë¼ ë©”ì‹œì§€ë¥¼ êµ¬ë¶„í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤. st.chat_inputì„ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.
    if prompt := st.chat_input("í•˜ê³  ì‹¶ì€ ë§ ì…ë ¥"):
        # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•©ë‹ˆë‹¤.
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):  # ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ ì…ë ¥ì„ í‘œì‹œí•©ë‹ˆë‹¤.
            st.markdown(prompt)
        with st.chat_message("assistant"):  # ì±—ë´‡ì˜ ì‘ë‹µì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
            message_placeholder = st.empty()  # ì‘ë‹µì„ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•œ ì„ì‹œ í”Œë ˆì´ìŠ¤í™€ë”
            full_response = ""  # ì‘ë‹µ ë‚´ìš©ì„ ì €ì¥í•  ë³€ìˆ˜
            # OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡ì˜ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
            # for delta in client.chat.completions.create(...)ë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ ë°›ê³  ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            for delta in client.chat.completions.create(
                model="gpt-4-turbo-preview",  # ì‚¬ìš©í•  ëª¨ë¸
                messages=[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ],
                stream=True,  # ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¼(ì‹¤ì‹œê°„ìœ¼ë¡œ) ë°›ìŠµë‹ˆë‹¤.
            ):
                # ì‘ë‹µ ë‚´ìš©ì„ ì¡°í•©í•˜ì—¬ full_responseë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                full_response += delta.choices[0].delta.content if delta.choices[0].delta.content else ""
                message_placeholder.markdown(full_response + "â–Œ")  # ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œí•˜ê³ , ì…ë ¥ ì¤‘ì„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

            message_placeholder.markdown(full_response)  # ìµœì¢… ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
        # ì±—ë´‡ì˜ ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•©ë‹ˆë‹¤.
        st.session_state.messages.append({"role": "assistant", "content": full_response})
